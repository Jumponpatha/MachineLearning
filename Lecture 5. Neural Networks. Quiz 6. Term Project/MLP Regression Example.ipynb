{"cells":[{"cell_type":"code","execution_count":1,"id":"e8ddf4ed","metadata":{"id":"e8ddf4ed","executionInfo":{"status":"ok","timestamp":1709368983865,"user_tz":-420,"elapsed":1628,"user":{"displayName":"Suthep Madarasmi","userId":"02283054729838819507"}}},"outputs":[],"source":["#copied from https://towardsdatascience.com/deep-neural-multilayer-perceptron-mlp-with-scikit-learn-2698e77155e\n","from sklearn.neural_network import MLPRegressor\n","from sklearn.model_selection import train_test_split\n","from sklearn.datasets import fetch_california_housing\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import r2_score\n","import pandas as pd"]},{"cell_type":"code","source":["#Split test and train data\n","cal_housing = fetch_california_housing() #house price is a function of many parameters\n","X = pd.DataFrame(cal_housing.data,columns=cal_housing.feature_names)\n","y = cal_housing.target\n","print(\"Training features X = \\n\", X)\n","print(\"\\nOutput house prices y = \\n\", y)\n","X_train, X_test, y_train, y_test = train_test_split(X, y,random_state=1, test_size=0.2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QwKn6gREoUMP","executionInfo":{"status":"ok","timestamp":1709369017841,"user_tz":-420,"elapsed":1718,"user":{"displayName":"Suthep Madarasmi","userId":"02283054729838819507"}},"outputId":"5797cc75-2efd-4a5c-e474-0808f2f9be19"},"id":"QwKn6gREoUMP","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Training features X = \n","        MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n","0      8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n","1      8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n","2      7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n","3      5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n","4      3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n","...       ...       ...       ...        ...         ...       ...       ...   \n","20635  1.5603      25.0  5.045455   1.133333       845.0  2.560606     39.48   \n","20636  2.5568      18.0  6.114035   1.315789       356.0  3.122807     39.49   \n","20637  1.7000      17.0  5.205543   1.120092      1007.0  2.325635     39.43   \n","20638  1.8672      18.0  5.329513   1.171920       741.0  2.123209     39.43   \n","20639  2.3886      16.0  5.254717   1.162264      1387.0  2.616981     39.37   \n","\n","       Longitude  \n","0        -122.23  \n","1        -122.22  \n","2        -122.24  \n","3        -122.25  \n","4        -122.25  \n","...          ...  \n","20635    -121.09  \n","20636    -121.21  \n","20637    -121.22  \n","20638    -121.32  \n","20639    -121.24  \n","\n","[20640 rows x 8 columns]\n","\n","Output house prices y = \n"," [4.526 3.585 3.521 ... 0.923 0.847 0.894]\n"]}]},{"cell_type":"code","source":["# Multi-layer Perceptron is sensitive to feature scaling, so it is highly recommended to scale your data.\n","#For example, scale each attribute on the input vector X to [0, 1] or [-1, +1], or standardize it to have\n","#  mean 0 and variance 1. Note that you must apply the same scaling to the test set for meaningful results.\n","#You can use StandardScaler for standardization.\n","\n","from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","scaler.fit(X_train)  #To find the mean and variance scalar to use for both X_train and X_test.\n","X_train_scaled = scaler.transform(X_train)  #then use that to scale the training set\n","# apply same transformation to test data\n","X_test_scaled = scaler.transform(X_test) #use the same mean and variance found in scaler.fit to transfor test set"],"metadata":{"id":"ES_GCdUzofCg","executionInfo":{"status":"ok","timestamp":1709369048771,"user_tz":-420,"elapsed":357,"user":{"displayName":"Suthep Madarasmi","userId":"02283054729838819507"}}},"id":"ES_GCdUzofCg","execution_count":3,"outputs":[]},{"cell_type":"code","source":["#Regression fit\n","#https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html\n","#NOTE THAT ACTIVATION FUNCTION IS ONLY FOR HIDDEN LAYERS.\n","reg = MLPRegressor(hidden_layer_sizes=(64,64,64),activation=\"relu\" ,random_state=1, max_iter=2000).fit(X_train_scaled, y_train)"],"metadata":{"id":"n96kelfUotnA","executionInfo":{"status":"ok","timestamp":1709369128519,"user_tz":-420,"elapsed":71015,"user":{"displayName":"Suthep Madarasmi","userId":"02283054729838819507"}}},"id":"n96kelfUotnA","execution_count":4,"outputs":[]},{"cell_type":"code","source":["#Test the regressor for prediction\n","y_pred=reg.predict(X_test_scaled)\n","#The coefficient of determination  is defined as R^2 = 1- u/v\n","#where u is the residual sum of squares ((y_true - y_pred)** 2).sum() and\n","#  v is the total sum of squares ((y_true - y_true.mean()) ** 2).sum().\n","#Closer to 1 is best. Over 0.5 is quite good.\n","print(\"The Score with \", (r2_score(y_pred, y_test)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bOWwo64mppPf","executionInfo":{"status":"ok","timestamp":1709369148317,"user_tz":-420,"elapsed":330,"user":{"displayName":"Suthep Madarasmi","userId":"02283054729838819507"}},"outputId":"0ed86a3f-66e6-4de0-b1ef-5050f678499d"},"id":"bOWwo64mppPf","execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["The Score with  0.7633133194206162\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"T4rMA9lMtSw2"},"id":"T4rMA9lMtSw2","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.10"},"colab":{"provenance":[{"file_id":"1n6-Lu1Gv9JNGos9bDtzFr2SYWifzKgDe","timestamp":1648870778301},{"file_id":"1oT__i8jAhEAWHBioooy5JjJYIWL2jPgw","timestamp":1648831786539}]}},"nbformat":4,"nbformat_minor":5}